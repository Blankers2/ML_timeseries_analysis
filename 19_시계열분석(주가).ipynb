### 데이터 준비

import numpy as np
import pandas as pd

- 데이터
    - https://kr.investing.com/crypto/bitcoin/historical-data

df = pd.read_csv('/content/drive/MyDrive/데이터분석스쿨2기/share/12.데이터활용및과학방법론-12/Bitcoin.csv',
            index_col=0 )
# 단위, 달러 단위
df

df.sort_index(inplace=True)

tmp = df.reset_index()
tmp.head(2)

tmp.info()

# 날짜 양식 조정
tmp['날짜'] = tmp['날짜'].apply( lambda x:x.replace('년 ','-').replace('월 ','-').replace('일',''))

tmp.head(1)

# 인덱스 다시 시간으로 위치
df = tmp.set_index( keys=['날짜'])
df.head(1)

close_price = df['종가']
close_price

close_price = close_price.apply(lambda x:x.replace(',',''))
close_price

close_price = close_price.astype( np.float64 )

close_price.dtype

# 종가 데이터를 이용한 차트 확인
close_price.index.name = 'date'
close_price.plot(rot=45);

### ARIMA 모형의 모수

- ARIMA 모형을 따르는 (아리마) 분포를 특징을 규정하는 척도
    - p
        - AR 모형의 차수(시간 지연 수)
        - 차수(lag)
    - d
        - 차분(Difference) 횟수
        - 데이터를 과거값에 빼는 행위를 한 횟수
    - q
        - MA 모형의 이동 평균 모델의 순서

- p,d,q 의 계산적 특징
    - p*q = 0
        - 둘중 하나는 반드시 0이다
            - 둘중 하나는 반드시 0< ~ < 2 사이 값
                - 만약 정수라면 1로 가정
        - 특정 데이터는 아리마모형으로 분석한 결과 한쪽의 경향을 강하게 띤다
    - p+q < 2
    - p, d, q는 일반적으로 음이 아닌 정수

- 모수 추정
    - **p**, d, **q**를 정하는 방법
    - ACF plot
        - Autocorrelation function
        - 자기 상관 함수
            - 관측치들 사이의 관련성 추정
    - PACF plot
        - Partial Autocorrelation function
        - 편 자기 상관 함수
            - 모든 관측치 X, 두 관측치의 관련성 추정
    - 해석
        - 시계열 데이터가 AR 특성을 가짐
            - ACF 천천히 감소
            - PACF 최초 시차를 제외, 급격하게 감소
        - 시계열 데이터가 MA 특성을 가짐
            - ACF 급격히 감소
            - PACF 천천히 감소


from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

plt.figure(figsize=(20, 5))
plot_acf( close_price)
plot_pacf( close_price)
plt.show()

# acf는 천천히 감소
# pacf는 급격히 감소
# 위의 특성상 비트코인 종가 데이터는 AR 특성을 띤다
# p*q = 0, p + q < 2 => p값은 1(정수기준), q=0 추정

# 차분 계산
# 1일단위 차분
close_price.diff(periods=1)

# 차분 시각화

# 차분 데이터 -> 결측 제거하여 사용
diff_data = close_price.diff(periods=1).iloc[1:]

# 종가
close_price.plot(rot=45)
plt.show()

# 차분
diff_data.plot(rot=45)
plt.show()

# 차분의 ACF, PACF
plot_acf(  diff_data)
plt.show()

plot_pacf( diff_data)
plt.show()

# 2017년 12월 초 -> 상당향의 급등락이 보임
# 차분값은 초반이후 ACF, PACF 상태가 안정화됨 -> 시계열 분석은 정상상태로 판단

### ARIMA 모형 분석

# ARIMA 모형 사용
from statsmodels.tsa.arima.model import ARIMA

# order 모수입력 => [p,d,q] : AR 특성, 차분적용(안정화되어 있음), MA 특성은 약함
model = ARIMA(close_price, order=[1, 1, 0])
model_fit = model.fit()

'''
    - P>|z| 값은 학습의 적정성을 확이하는 t-test 요소
    - P>|z|=0.000 < 0.05 보다 작으므로 ARIMA 모형은 적합함
'''

# 요약
print( model_fit.summary() )

close_price

# 모델을 통해서 주가를 예측 수행
from statsmodels.graphics.tsaplots import plot_predict

close_price.plot( rot=45 )
# 예측 모델로 가격을 시각화
plot_predict(model_fit, '2017-10-12', '2017-12-11')
plt.show()

# 실제 주가의 추세를 잘 따라가고 있다

# 실제 가격 예측
# 10일치 예측
model_fit.forecast( steps=10 )

# QnA때 확인

- 시계열 분석에 적용되는 데이터
    - 단수 종가가 아닌
    - 자체 알고리즘(정량적, 정성적인요소, 수식등등 )에 의한 데이터로 진행
    - 단, IOT, 스마트팩토리 -> 정량적분석 가능

# 혼합형 시계열 분석

## fbprophet

- 종류
    - 모형/방법
        - AR
        - **Prophet** : Meta 의 제품
            - https://facebook.github.io/prophet/docs/quick_start.html
            - fb-Prophet

!pip install fbprophet -q

# 웹클릭 데이터를 이용한 시계열 분석 -> 웹로그
web_traffic = pd.read_csv('/content/drive/MyDrive/데이터분석스쿨2기/share/12.데이터활용및과학방법론-12/webTraffic.csv')
# 1년치 데이터로 예상
web_traffic.shape

df = web_traffic.copy(True)
df.shape

df.head(2)

df.tail(2)

# 결측 제거
df.dropna(inplace=True)

# 컬럼명 조정 => DS	Y(대소문자 관계 없이 고정)
df.columns = ['ds','y']
df.head(1)

df.info()

# ds 형식 변경 yyyy-MM-dd
df['ds'] = pd.to_datetime( df['ds'], format='%y. %m. %d.')
df.head(1)

df['y'] = df.y.apply( lambda x:x.replace(',',''))
df['y']

# 최종데이터 - 데이터 클리닝 작업, fbprophet 형태에 맞게 가공함
# 통계 모델, 혼합형 모델(서드 파트 제품) => 1개 피처만 사용 => 피처에 여러
# 요소를 가미하지 않으면 1개 피처만으로 예측 문제가 발생 => 성능 저하
from prophet import Prophet

# 주기성 설정및 다양한 요소 적용 가능함
# 년간, 일간 주기성 분석
model = Prophet( yearly_seasonality=True, daily_seasonality=True)

# 훈련
model.fit( df )

# 예측 : periods를 지정 => 해당 기간만큼 예측
future = model.make_future_dataframe( periods=60 )
# 훈련 데이터양 + 이후 60일 데이터가 생성
# 424 = 364 + 60
future.shape

df.tail(2)

# 7월 ~8월까지 예측 날짜
future.tail(2)

# ds값이 포한된 데이터를 이용 => 예측
forecast = model.predict( future )

# 최종 결과 + 각종 지표들 출력(이 지표을 이용하면 인사이트 도출이 편함)
forecast.tail()

# 예측결과 시각화
model.plot( forecast )

# 점이 찍힌곳 => 기존 데이터(원본)
# 점이 없는곳 => 예측해서 그린 구간
# 예측 결과에 의하면 클릭수가 줄어들고 있다 -> 사이트에 대한 관심도가 적어지고 있다...

# 주기성등 기타 분석
model.plot_components( forecast )

# 트랜드 : 클릭수는 향상되고 있음
# 주간 기준 트랜드 : 월, 화요일 피크, 주말로 갈수록 하락세 (사용자는 월화에 많이 몰림)
# 여름, 겨울에 클릭수가 바닥을 찍는다? => 봄/가을에 클릭수가 높음
# 20시 30분 기점부터 12시까지 큰 증가세를 보임, 03시 까지 다시 하락

# 머신러닝/딥러닝 시계열 분석

- 종류
    - 모델/모형
        - 순환신경망
            - RNN/**LSTM**/GRU
                - 데이터를 조정
                    - 주식
                    - 7일 기준 학습 -> 8일차 예측
                        - 매일 하루씩 쉬프트 하여 데이터 구축
                - 모델 + 학습 + 예측 + 시각화
        - transformers
        - 앙상블기법
        - ...

## LSTM기반 시계열데이터(금융분야-주가) 예측모델 구축

### 데이터 획득

- NVDA 주가 데이터
    - 인공지능 대장주
        - https://finance.yahoo.com/quote/NVDA/history?period1=1672531200&period2=1716525863
        - 2023.1.3 ~ 2024.5.24
            - 시초가, 최고가, 최저가, 종가, 수정종가, 거래량

import numpy as np
import pandas as pd

stock_df = pd.read_csv('/content/drive/MyDrive/데이터분석스쿨2기/share/12.데이터활용및과학방법론-12/NVDA.csv')
print( stock_df.shape )
stock_df.tail()

- 수정종가
    - 기업의 이익배분하는 활동(주주환원->배당,..)으로 지급액을 기업의 재투자로 사용한다는 전제하에 계산된 종가
    - 확정 데이터로 보기에는 애매한 측면이 있어서 일단 배제

stock_df.drop(['Adj Close'], axis=1, inplace=True)
stock_df.head(1)

### 예측할 항목 결정(타겟)

- **Open**
    - 현재기준
        - 프리마켓(17시)
        - 시카고거래소오픈(21시30분)
        - 뉴욕거래소오픈(22시30분) : 기준값
        - 수업진행
    - 트레이더 관점
        - 숏 트레이더 포지션
- Close
    - 뉴욕거래소 종가 : 기준값
    - 애프터마켓 종가
    - QnA 진행
    - 트레이더 관점
        - 오버 나잇
        - 장기투자자

# 시초가 데이터 획득 -> 차후 시각화 시초가 + 실제시초가(금일기준 -7일) + 예측시초가(금일기준 -7일)
# y축
stock_open_data = stock_df['Open'].values
stock_open_data[:2], stock_open_data.shape

# x축 -> 시간정보 -> Date 컬럼 -> 타입변경
stock_times = pd.to_datetime( stock_df['Date'] )
stock_times[:2], stock_times.shape

import matplotlib.pyplot as plt

%matplotlib inline

# 오픈가 기준 선형 차트
# x축 시간, y축 주가
plt.figure( figsize=(15, 5) )

# 원본 데이터 시초가
plt.plot( stock_times, stock_open_data, color='black', label='NVDA Open Ori')
# plt.plot( stock_times, stock_df['Close'].values, color='blue',
#           linestyle='--',
#           label='NVDA Close Ori')

# 축 이름
plt.xlabel('Day')
plt.ylabel('Open Price')

# 범례
plt.legend()
plt.show()

### 데이터 준비

- 대상 데이터만 추출
    - 시초가, 고가, 저가, 종가, 볼륨
    - 학습을 대비하여 기준일 단위로 피처데이터와 타겟데이터구성
        - 14일 기준
            - D ~ D+14 : 피처데이터
            - D+15 : 타겟데이터
        - 매일 하루씩 뒤고 가면서 데이터를 구축

cols = list( stock_df.columns[1:] )
cols

stock_df.info()

# 딥러닝시 데이터는 모두 수치형 -> 편의상 float로 통일해서 관리
stock_num_df = stock_df[ cols ].astype( float )
stock_num_df

- 피처엔지니어링
    - 정규화 처리
        - 주가 상승이 너무 커서 (7~8배) 단위가 않맞음
        - 거래량과 주가도 단위가 않맞음
        - StandardScaler 활용

from sklearn.preprocessing import StandardScaler

# 원래값 => 스케일링 => 특정값 범위에서 처리
# 평균0, 표준편차 1.0의 정규분포를 따르는 StandardScaler()를 이용하여 스케일링 처리함
stock_scaler = StandardScaler().fit(stock_num_df)
stock_num_df_scaled = stock_scaler.transform( stock_num_df )
stock_num_df_scaled

# 차후, 예측 => 스케일러 => 원복

- 훈련용, 테스트용
    - 훈련용
        - 데이터 처음부터 90%까지 사용<-설정
        - 전체데이터 350일치중 90%부분만 훈련용으로 사용
        - 나머지 10%는 예측을 수행하여 실제 정답과 비교하여 모델의 성능을 가늠할수 있음
    - 테스트용
        - 이 부분 날짜(최신일 기준, 10%)<-설정

# 훈련데이터, 테스트 데이터 분할시 train_test_split()을 사용한다면, 절대로 셔플 X
# 시간순 데이터이기 때문에 셔플금지
# 총 데이터에서 90% 지점의 개수
DIV_RATE = 0.9
num, _ = stock_num_df_scaled.shape
# 정수처리 -> 슬라이싱시 사용하게 처리
index_90_line = int(num*DIV_RATE)
index_90_line

# 정규화된 데이터로부터, 90% 데이터 추출 -> 훈련용 준비
train_data_scaled = stock_num_df_scaled[:index_90_line]
train_data_time   = stock_times[:index_90_line]

train_data_scaled.shape, train_data_time.shape

# 정규화된 데이터로부터, 10% 테스트 데이터 추출 -> 테스트용 준비
test_data_scaled = stock_num_df_scaled[index_90_line:]
test_data_time   = stock_times[index_90_line:]

test_data_scaled.shape, test_data_time.shape

- 최종 훈련/테스트데이터 목표
    - 피처데이터
        - 14일단위로 훈련, 15일차를 맞춘다
            - 훈련 데이터 입력 (315, 5)
            - 변환작업후 ( 315-14, 14, 5)
                - (301, 14, 5)
            - 테스트 데이터 입력 (35, 5)
            - 변환작업후 ( 35-14, 14, 5)
                - (21, 14, 5)
    - 타겟데이터
        - 훈련용 정답데이터
            - (301, 1)
        - 테스트용 정답데이터
            - (21, 1)

# 기준값 정의
PREDICT_DAY     = 1  # 14일치 데이터를 기준으로 다음날 1Day 예측
FEATURE_STD_DAY = 14 # 14일치 데이터를 보고 다음날 예측
INPUT_DIM       = 5  # 예측을 위한 하루단위 피처 개수 Open,High,Low,Close,Volume

# 데이터가 크면 처음부터 배열 단위 고려
X_train, X_test, y_train, y_test = list(), list(), list(), list()

# 실습 5분
# 훈련용 range( 14, 90%데이터개수-PREDICT_DAY+1, PREDICT_DAY )
# 구현
for i in range( FEATURE_STD_DAY, index_90_line-PREDICT_DAY+1, PREDICT_DAY ):
    # [ 0:14,..] => [1:15, ..]=> [2:16, ..]
    X_train.append( train_data_scaled[ i - FEATURE_STD_DAY:i, : ] )
    # 14일이경과되고 다음날의 시초가(open) -> 컬럼값 0
    # [ 14:15, 0] => [15:16, 0] => [16:17, 0]
    y_train.append( train_data_scaled[ i + PREDICT_DAY -1:i + PREDICT_DAY , 0 ] )
    pass

# 테스트용 range( 14, 10%데이터개수-PREDICT_DAY+1, PREDICT_DAY )
index_10_num = len( test_data_scaled )
for i in range( FEATURE_STD_DAY, index_10_num-PREDICT_DAY+1, PREDICT_DAY ):
    X_test.append( test_data_scaled[i - FEATURE_STD_DAY:i, : ] )
    y_test.append( test_data_scaled[i + PREDICT_DAY -1:i + PREDICT_DAY , 0 ] )
    pass
# 구현


X_train, y_train = np.array(X_train), np.array(y_train)
X_test, y_test   = np.array(X_test), np.array(y_test)

# 데이터를 배열로 담아서 최종 확인
X_train.shape, X_test.shape, y_train.shape, y_test.shape
# (301, 14, 5), (21, 14, 5), (301, 1), (21, 1)

### 모델 구축 및 학습

- tensorflow + keras
- LSTM
    - 2개층 구성
        - 1f -> 64 (설정)
            - hidden state 전달되게 설정
            - 다음 층도 LSTM 이므로
        - 2f -> 32 (설정)
            - hidden state 전달되게 X
            - 다음 층은 Dense 이므로 y로만 출력되게 구성
        - output -> 1의 값으로 수렴(연속형데이터, 주가를 예측) -> 최소 오차로 예측

- 특징
    - 순환신경망 :
        - 입력
            - 이전 시점의 은닉상태 h<sub>t-1</sub> + x<sub>t</sub> 입력
        - 출력
            - h<sub>t</sub>
            - y<sub>t</sub>

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

_, ouptut_size = y_train.shape
# 둘다 표현 가능
# _, feat_day, feat_col = X_train.shape
# input_shape    =  (feat_day, feat_col)
input_shape    =  (FEATURE_STD_DAY, INPUT_DIM)

model = Sequential()
model.add( LSTM( 64, return_sequences=True, input_shape=input_shape) )
# return_sequences=False -> hidden state 전달 x
model.add( LSTM( 32, return_sequences=False) )
model.add( Dense( ouptut_size ) ) # 1개의 예측값(시초가)로 나온다

model.summary()

from tensorflow.keras.optimizers import Adam

# 컴파일 환경
# 모델의 목표가 주가를 최대한 가깝게 맞추는 회구형 문제이므로 - 손실함수는 mse, rmse,... 구성
model.compile( optimizer=Adam(learning_rate=0.01), loss='mse')

history = model.fit( X_train, y_train,
                     epochs=50, batch_size=32,
                     validation_split=0.1,
                     verbose=1
                     )

# 가중치 저장
model.save_weights('stock_lstm_weight.h5')

plt.plot( history.history['loss'], label='loss')
plt.plot( history.history['val_loss'], label='val_loss')
plt.legend()
plt.show()

### 주가 예측

- 방법
    - 테스트데이터 -> 예측 -> 예측값 -> 스케일러 -> 복원
    - 오늘 주가 정보(시초가, 최고가,...) -> 내일 시초가 예측되서 나온다(오차값)

y_pred = model.predict( X_test )
y_pred

# np.newaxis : 배열의 차원을 확장 -> 언스퀴즈 느낌
stock_scaler.mean_[ np.newaxis, :]

# np.repeat() : 배열요소를 반복해서 구성해준다
# (21, 5) => 더미값(임의값, stock_scaler.mean_ 등) 활용하여 (21, 5)를 구성함
temp_mean_value = np.repeat( stock_scaler.mean_[ np.newaxis, :], len(y_pred), axis=0)
temp_mean_value.shape

# 시초가 자리에 예측값 세팅
temp_mean_value[ :, 0] = np.squeeze(y_pred)

# 스케일링 -> [ [예측값대체, , , , ], [예측값대체, ], ...]
# 예측한값은 시초가값만 존재 -> 4개의 영역이 추가로 필요
# 단위 환산 ->
# 예측 주가값
stock_open_pred = stock_scaler.inverse_transform(temp_mean_value)[:, 0]
stock_open_pred

pred_count = stock_open_pred.shape[0]
pred_count

import matplotlib.pyplot as plt

plt.figure( figsize = (15, 5) )

# 오픈가
plt.plot( stock_times, stock_open_data, color='green',
          label='Original Oepn Price')

# 테스트 데이터상 오픈가
# 위의 오픈가에 겹쳐서 그림
plt.plot( test_data_time[-pred_count:], stock_open_data[-pred_count:],
          color='blue', label='Test Oepn Price'
          )

# 예측결과에 따른 오픈가
plt.plot( test_data_time[-pred_count:], stock_open_pred[-pred_count:],
          color='red', linestyle='--', label='Test Oepn Price'
          )

# 데코 : 축 이름, 범례, 제목등
plt.xlabel('Date')
plt.ylabel('Open Stock Price')
plt.title('NVIDA Stock')
plt.legend()

# 화면출력
plt.show()

- 차트 해석
    - 실제 주가가 예측한 주가보다 더 많이 상승
        - 타 종목을 대부분 하락장, NVIDA만 상승
        - 요인
            - 정성적 요인 크게 작용
                - 하락 : 큰손들의 손절
                - 상승
                    - 실적 발표 기대감(예상되로 진행)
                    - 액면 분할 기대감(예상되로 진행)
                    - 등등.. 대상승
    - 금융
        - 시계열 분석
            - 정량분석 + 정성분석  => 정교한 예측값이 가능
            - AI 알고리즘 해지펀드들
                - 퀀트를 고용 개발 -> 자동매매
                - 매일 알고리즘 수정 진행
